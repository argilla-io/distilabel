{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ¤—Â End-to-end distilabel example with Inference Endpoints and Notus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ignacio/.local/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from typing import Dict\n",
    "\n",
    "from distilabel.llm import InferenceEndpointsLLM\n",
    "from distilabel.pipeline import Pipeline\n",
    "from distilabel.tasks import Llama2TextGenerationTask, SelfInstructTask, Prompt\n",
    "\n",
    "from datasets import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up an inference endpoint with Notus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Llama2QuestionAnsweringTask(Llama2TextGenerationTask):\n",
    "    def generate_prompt(self, question: str) -> str:\n",
    "        return Prompt(\n",
    "            system_prompt=self.system_prompt,\n",
    "            formatted_prompt=question,\n",
    "        ).format_as(\"llama2\")  # type: ignore\n",
    "\n",
    "    def parse_output(self, output: str) -> Dict[str, str]:\n",
    "        return {\"answer\": output.strip()}\n",
    "\n",
    "    def input_args_names(self) -> list[str]:\n",
    "        return [\"question\"]\n",
    "\n",
    "    def output_args_names(self) -> list[str]:\n",
    "        return [\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HF_INFERENCE_ENDPOINT_NAME\"] = \"aws-notus-7b-v1-4052\"\n",
    "os.environ[\"HF_TOKEN\"] = \"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\"\n",
    "os.environ[\"HF_NAMESPACE\"] = \"argilla\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = InferenceEndpointsLLM(\n",
    "    endpoint_name=os.getenv(\"HF_INFERENCE_ENDPOINT_NAME\"),  # type: ignore\n",
    "    endpoint_namespace=os.getenv(\"HF_NAMESPACE\"),  # type: ignore\n",
    "    token=os.getenv(\"HF_TOKEN\") or None,\n",
    "    task=Llama2QuestionAnsweringTask(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[{'model_name': 'argilla/notus-7b-v1', 'prompt_used': \"<s>[INST] <<SYS>>\\nYou are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.<</SYS>>\\n\\nWhat's the capital of Spain? [/INST]\", 'raw_output': \"\\n\\nThe capital of Spain is Madrid. It is the largest city in Spain and the third-largest city in the European Union. Madrid is known for its rich history, art, and culture, and is home to many famous landmarks, such as the Prado Museum, the Royal Palace of Madrid, and the Retiro Park. Madrid is also a major economic and financial center in Europe, and is home to many international companies and organizations. The city is known for its vibrant nightlife, delicious cuisine, and friendly people. Madrid is a great destination for travelers looking to experience the best of Spain's culture\", 'parsed_output': {'answer': \"The capital of Spain is Madrid. It is the largest city in Spain and the third-largest city in the European Union. Madrid is known for its rich history, art, and culture, and is home to many famous landmarks, such as the Prado Museum, the Royal Palace of Madrid, and the Retiro Park. Madrid is also a major economic and financial center in Europe, and is home to many international companies and organizations. The city is known for its vibrant nightlife, delicious cuisine, and friendly people. Madrid is a great destination for travelers looking to experience the best of Spain's culture\"}}]]\n"
     ]
    }
   ],
   "source": [
    "print(llm.generate([{\"question\": \"What's the capital of Spain?\"}]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating instructions with SelfInstructTask\n",
    "\n",
    "We've never tried so it might actually not work, fallback: skip this and we can find an instruction dataset on the Hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = [\n",
    "    \"Fantasy\",\n",
    "    \"Historic Novels\",\n",
    "    \"Sci-fi Stories\",\n",
    "    \"Fictional Characters\",\n",
    "    \"Superheroes\",\n",
    "    \"Superpowers\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_dict({\n",
    "    \"input\": topics\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_task = SelfInstructTask(\n",
    "    application_description=\"A assistant that creates fictional characters and their backstories.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_generator = InferenceEndpointsLLM(\n",
    "    endpoint_name=os.getenv(\"HF_INFERENCE_ENDPOINT_NAME\"),  # type: ignore\n",
    "    endpoint_namespace=os.getenv(\"HF_NAMESPACE\"),  # type: ignore\n",
    "    token=os.getenv(\"HF_TOKEN\") or None,\n",
    "    task=instruction_task,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    generator=instruction_generator\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/ignacio/.local/lib/python3.11/site-packages/rich/live.py:231: UserWarning: install \"ipywidgets\" for Jupyter \n",
       "support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/ignacio/.local/lib/python3.11/site-packages/rich/live.py:231: UserWarning: install \"ipywidgets\" for Jupyter \n",
       "support\n",
       "  warnings.warn('install \"ipywidgets\" for Jupyter support')\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/05/23 12:29:52] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> INFO:distilabel:Processing batch <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                             <a href=\"file:///Users/ignacio/Documents/recognai/distilabel/src/distilabel/pipeline.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">pipeline.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/ignacio/Documents/recognai/distilabel/src/distilabel/pipeline.py#525\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">525</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12/05/23 12:29:52]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m INFO:distilabel:Processing batch \u001b[1;36m1\u001b[0m of \u001b[1;36m2\u001b[0m\u001b[33m...\u001b[0m                             \u001b]8;id=87402;file:///Users/ignacio/Documents/recognai/distilabel/src/distilabel/pipeline.py\u001b\\\u001b[2mpipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=2301;file:///Users/ignacio/Documents/recognai/distilabel/src/distilabel/pipeline.py#525\u001b\\\u001b[2m525\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> INFO:distilabel:Calling generator for batch <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                       <a href=\"file:///Users/ignacio/Documents/recognai/distilabel/src/distilabel/pipeline.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">pipeline.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/ignacio/Documents/recognai/distilabel/src/distilabel/pipeline.py#529\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">529</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m INFO:distilabel:Calling generator for batch \u001b[1;36m1\u001b[0m\u001b[33m...\u001b[0m                       \u001b]8;id=820199;file:///Users/ignacio/Documents/recognai/distilabel/src/distilabel/pipeline.py\u001b\\\u001b[2mpipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=815200;file:///Users/ignacio/Documents/recognai/distilabel/src/distilabel/pipeline.py#529\u001b\\\u001b[2m529\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/ignacio/Documents/recognai/distilabel/src/distilabel/llm/huggingface/inference_endpoints.py:177: \n",
       "UserWarning: No `prompt_format` has been specified and no `default_format` is set, so the prompt will be \n",
       "concatenated with a line-break and no specific formatting by default.\n",
       "  prompts = self._generate_prompts(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/ignacio/Documents/recognai/distilabel/src/distilabel/llm/huggingface/inference_endpoints.py:177: \n",
       "UserWarning: No `prompt_format` has been specified and no `default_format` is set, so the prompt will be \n",
       "concatenated with a line-break and no specific formatting by default.\n",
       "  prompts = self._generate_prompts(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/05/23 12:30:28] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> INFO:distilabel:Processing batch <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                             <a href=\"file:///Users/ignacio/Documents/recognai/distilabel/src/distilabel/pipeline.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">pipeline.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/ignacio/Documents/recognai/distilabel/src/distilabel/pipeline.py#525\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">525</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12/05/23 12:30:28]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m INFO:distilabel:Processing batch \u001b[1;36m2\u001b[0m of \u001b[1;36m2\u001b[0m\u001b[33m...\u001b[0m                             \u001b]8;id=687240;file:///Users/ignacio/Documents/recognai/distilabel/src/distilabel/pipeline.py\u001b\\\u001b[2mpipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=958462;file:///Users/ignacio/Documents/recognai/distilabel/src/distilabel/pipeline.py#525\u001b\\\u001b[2m525\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> INFO:distilabel:Calling generator for batch <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>                       <a href=\"file:///Users/ignacio/Documents/recognai/distilabel/src/distilabel/pipeline.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">pipeline.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/ignacio/Documents/recognai/distilabel/src/distilabel/pipeline.py#529\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">529</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m                   \u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m INFO:distilabel:Calling generator for batch \u001b[1;36m2\u001b[0m\u001b[33m...\u001b[0m                       \u001b]8;id=708963;file:///Users/ignacio/Documents/recognai/distilabel/src/distilabel/pipeline.py\u001b\\\u001b[2mpipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=109944;file:///Users/ignacio/Documents/recognai/distilabel/src/distilabel/pipeline.py#529\u001b\\\u001b[2m529\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Flattening the indices: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 607.17 examples/s]\n",
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 627.63 examples/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "distiset = pipeline.generate(dataset=dataset, num_generations=4, batch_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of generated instructions: 144\n",
      "1. What is the origin story of the character's magical abilities?\n",
      "2. How did the character's childhood experiences shape their personality?\n",
      "3. What is the character's relationship with their family and friends?\n",
      "4. What is the character's motivation for embarking on their current quest?\n",
      "5. What is the character's greatest fear and how does it affect their actions?\n",
      "6. What is the character's favorite food and why?\n",
      "7. What is the character's preferred method of transportation and why?\n",
      "8. What is the character's favorite type of weapon and\n",
      "1. What is the origin story of the character's magical abilities?\n",
      "2. How did the character's childhood experiences shape their personality?\n",
      "3. What is the character's relationship with their family and friends?\n",
      "4. What is the character's motivation for embarking on their current quest?\n",
      "5. What is the character's greatest fear and how does it affect their actions?\n",
      "6. What is the character's favorite food and why?\n",
      "7. What is the character's preferred method of transportation and why?\n",
      "8. What is the character's favorite type of weapon and\n",
      "1. What is the origin story of the character's magical abilities?\n",
      "2. How did the character's childhood experiences shape their personality?\n",
      "3. What is the character's relationship with their family and friends?\n",
      "4. What is the character's motivation for embarking on their current quest?\n"
     ]
    }
   ],
   "source": [
    "instructions = []\n",
    "for generations in distiset[\"generations\"]:\n",
    "    for generation in generations:\n",
    "        instructions.extend(generation)\n",
    "print(f\"Number of generated instructions: {len(instructions)}\")\n",
    "for instruction in instructions[:20]:\n",
    "    print(instruction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "distilabel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
