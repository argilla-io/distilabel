{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ü§ó¬†Use Notus on inference endpoints to create a legal preference dataset\n",
    "\n",
    "In this tutorial, you will learn how to use the Notus model on Inference Endpoints to create a legal preference dataset based on RAG instructions from the European AI Act. A full end-to-end example of how to use distilabel to leverage LLMs!\n",
    "\n",
    "[distilabel](https://github.com/argilla-io/distilabel) is an AI Feedback (AIF) framework that can generate and label datasets using LLMs, and can be used for many different use cases. Implemented with robustness, efficiency and scalability in mind, it allows anyone to build their synthetic datasets that can be used in many different scenarios. This tutorial shows an end-to-end example in which we will create a model expert in the new AI Act, to which we can make different types of questions and requests.\n",
    "\n",
    "The LLM model that we will fine-tune for this is [Notus 7B](https://argilla.io/blog/notus7b/), a fine-tuned version of Zephyr 7B that uses Direct Preference Optimization (DPO) and AIF techniques to outperform its foundation model in several benchmarks, and is completely open-source.\n",
    "\n",
    "This tutorial includes the following steps:\n",
    "\n",
    "- Defining a custom generating task for a `distilabel` pipeline.\n",
    "- Creating a RAG pipeline using Haystack for the EU AI Act.\n",
    "- Generating an instruction dataset with `SelfInstructTask`.\n",
    "- Generating a preference dataset using an `UltraFeedback` text quality task.\n",
    "\n",
    "You can use the Open in Colab button at the top of this page. This option allows you to run the notebook directly on Google Colab. Don't forget to change the runtime type to GPU for faster model training and inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/argilla-io/distilabel/blob/main/docs/tutorials/pipeline-notus-instructions-preferences-legal.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Let's start by installing the required depencies to run distilabel, Argilla and the rest of the packages used in the tutorial; most notably, Haystack.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install argilla distilabel farm-haystack pip install \"distilabel[hf-inference-endpoints]\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running Argilla\n",
    "\n",
    "For this tutorial, you can use Argilla to visualize and annotate the different datasets created by distilabel. There are two main options for deploying and running Argilla:\n",
    "\n",
    "**Deploy Argilla on Hugging Face Spaces:** If you want to run tutorials with external notebooks (e.g., Google Colab) and you have an account on Hugging Face, you can deploy Argilla on Spaces with a few clicks:\n",
    "\n",
    "[![deploy on spaces](https://huggingface.co/datasets/huggingface/badges/raw/main/deploy-to-spaces-lg.svg)](https://huggingface.co/new-space?template=argilla/argilla-template-space)\n",
    "\n",
    "For details about configuring your deployment, check the [official Hugging Face Hub guide](https://huggingface.co/docs/hub/spaces-sdks-docker-argilla).\n",
    "\n",
    "**Launch Argilla using Argilla's quickstart Docker image**: This is the recommended option if you want [Argilla running on your local machine](../../getting_started/quickstart.ipynb). Note that this option will only let you run the tutorial locally and not with an external notebook service.\n",
    "\n",
    "For more information on deployment options, please check the Deployment section of the documentation.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "Tip\n",
    "\n",
    "This tutorial is a Jupyter Notebook. There are two options to run it:\n",
    "\n",
    "- Use the Open in Colab button at the top of this page. This option allows you to run the notebook directly on Google Colab. Don't forget to change the runtime type to GPU for faster model training and inference.\n",
    "- Download the .ipynb file by clicking on the View source link at the top of the page. This option allows you to download the notebook and run it on your local machine or on a Jupyter notebook tool of your choice.\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import dependencies\n",
    "\n",
    "The main dependencies for this tutorial are distilabel for creating the synthetic datasets and Argilla for visualizing and annotating these datasets, and also for fine-tuning our model. The package [Haystack](https://haystack.deepset.ai/) is used to creates batches from the original PDF document we want to create our datasets from.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict\n",
    "\n",
    "import argilla as rg\n",
    "\n",
    "from distilabel.llm import InferenceEndpointsLLM\n",
    "from distilabel.pipeline import Pipeline, pipeline\n",
    "from distilabel.tasks import Llama2TextGenerationTask, SelfInstructTask, Prompt\n",
    "\n",
    "from datasets import Dataset\n",
    "from haystack.nodes import PDFToTextConverter, PreProcessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are running Argilla using the Docker quickstart image or Hugging Face Spaces, you need to init the Argilla client with the URL and API_KEY:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace api_url with the url to your HF Spaces URL if using Spaces\n",
    "# Replace api_key if you configured a custom API key\n",
    "rg.init(\n",
    "    api_url=\"https://ignacioct-argilla.hf.space\",\n",
    "    api_key=\"owner.apikey\",\n",
    "    workspace=\"admin\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, we need to provide our HuggingFace and OpenAI accest token. To later instatiate an `InferenceEndpointsLLM` object, we need to pass as parameters the HF Inference Endpoint name and the HF namespace. One very convenient way to do so is also through environment variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"HF_TOKEN\"] = \"\"\n",
    "os.environ[\"HF_INFERENCE_ENDPOINT_NAME\"] = \"aws-notus-7b-v1-3184\"\n",
    "os.environ[\"HF_NAMESPACE\"] = \"argilla\"\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up an inference endpoint with Notus\n",
    "\n",
    "Inference endpoints are a solution, managed by Hugging Face, to easily deploy any Transformer-like model. They are built from models on the Hugging Face Hub. Inference endpoints are really handy for making inference on LLMs without the hastle of trying to run the models locally. In this tutorial, we will use inference endpoints to generate text using our Notus model, as part of the `distilabel` workflow. The endpoint of choice has a [Notus 7B instance](https://ui.endpoints.huggingface.co/argilla/endpoints/aws-notus-7b-v1-4052) running.\n",
    "\n",
    "### Defining a custom generating task for a distilabel pipeline\n",
    "\n",
    "To kickstart this tutorial, let's see how to set up and endpoint for our Notus model. It's not part of the end-to-end example we'll see later, but an example of how to connect to a Hugging Face endpoint and a test of the `distilabel` pipeline.\n",
    "\n",
    "Let's dive into this quick example of how to use an inference endpoint. We have prepared an easy `Llama2QuestionAnsweringTask` to ask question to the model, in a very similar way as we talk with the LLMs using chatbots. First, we define a class for the question-answering task, with functions showing `distilabel` how the model should generate the prompts, parse the input and the output, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuestionAnsweringTask(Llama2TextGenerationTask):\n",
    "    def generate_prompt(self, question: str) -> str:\n",
    "        return Prompt(\n",
    "            system_prompt=self.system_prompt,\n",
    "            formatted_prompt=question,\n",
    "        ).format_as(\n",
    "            \"llama2\"\n",
    "        )  # type: ignore\n",
    "\n",
    "    def parse_output(self, output: str) -> Dict[str, str]:\n",
    "        return {\"answer\": output.strip()}\n",
    "\n",
    "    def input_args_names(self) -> list[str]:\n",
    "        return [\"question\"]\n",
    "\n",
    "    def output_args_names(self) -> list[str]:\n",
    "        return [\"answer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`llm` is an object of the `InferenceEndpointsLLM` class, and by using it we can start generating answers to question using the `llm.generate()` method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = InferenceEndpointsLLM(\n",
    "    endpoint_name=os.getenv(\"HF_INFERENCE_ENDPOINT_NAME\"),  # type: ignore\n",
    "    endpoint_namespace=os.getenv(\"HF_NAMESPACE\"),  # type: ignore\n",
    "    token=os.getenv(\"HF_TOKEN\") or None,\n",
    "    task=QuestionAnsweringTask(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the `InferenceEndpointsLLM` object defined with the endpoint information and the Task, we can go ahead and start generating text. Let's ask this LLM what's, for example, the second most populated city in Denmark. The answer should be Aarhus.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The second most populated city in Denmark is Aarhus, with a population of around 340,000 people. It is located on the east coast of Jutland, and is known for its vibrant cultural scene, beautiful beaches, and historic landmarks. Aarhus is also home to Aarhus University, one of the largest universities in Scandinavia.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generation = llm.generate(\n",
    "    [{\"question\": \"What's the second most populated city in Denmark?\"}]\n",
    ")\n",
    "generation[0][0][\"parsed_output\"][\"answer\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The endpoint is working correctly! We have succesfully set up a custom generating task for a `distilabel` pipeline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a RAG pipeline using Haystack for the European AI Act\n",
    "\n",
    "For this end-to-end example, we would like to create an expert model capable of answering question and filling up information about the new AI Act promoted by the European Union, which is the first regulation on artificial intelligence. As part of its digital strategy, the EU wants to regulate artificial AI to ensure better conditions for the development and use of this innovative technology. This act is a regulatory framework for AI, with different risk levels meaning more or less regulation. They are the world's first rules on AI.\n",
    "\n",
    "This RAG pipeline that we want to create downloads the PDF file, converts it to plain text and preprocess it, creating batches that we can feed `distilabel` to start creating instructions from it. Let's see this first part of the pipeline and get the input data. Note that this RAG part of the pipeline is not based on an active pipeline based queries or semantic properties, but a more brute-force approach in which we download the PDF and preprocess its contents.\n",
    "\n",
    "### Downloading the AI Act PDF\n",
    "\n",
    "Firstly, we need to download the PDF document itself. We'll place it in our working directory, if it's not there already.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "if [ ! -f \"The-AI-Act.pdf\" ]; then\n",
    "    wget -q https://artificialintelligenceact.eu/wp-content/uploads/2021/08/The-AI-Act.pdf\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have it in our working directory, we can use Haystack's Converter and Pipeline features to extract the textual data, clean it and divide it in different batches. Afterwards, these batches will be used to start creating synthetic instructions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The converter turns the PDF into text we can process easily\n",
    "converter = PDFToTextConverter(remove_numeric_tables=True, valid_languages=[\"en\"])\n",
    "\n",
    "# Preprocessing pipelines can have several steps.\n",
    "# Ours clean empty lines, header, footers and whitespaces\n",
    "# and split the text into 150-char long batches, respecting\n",
    "# where the sentences naturally end and begin.\n",
    "preprocessor = PreProcessor(\n",
    "    clean_empty_lines=True,\n",
    "    clean_whitespace=True,\n",
    "    clean_header_footer=True,\n",
    "    split_by=\"word\",\n",
    "    split_length=150,\n",
    "    split_respect_sentence_boundary=True,\n",
    ")\n",
    "\n",
    "doc = converter.convert(file_path=\"The-AI-Act.pdf\", meta=None)[0]\n",
    "docs = preprocessor.process([doc])\n",
    "print(f\"Documents: 1\\nBatches: {len(docs)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look at the batches we just generated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['EN EN\\nEUROPEAN\\nCOMMISSION\\nProposal for a\\nREGULATION OF THE EUROPEAN PARLIAMENT AND OF THE COUNCIL\\nLAYING DOWN HARMONISED RULES ON ARTIFICIAL INTELLIGENCE\\n(ARTIFICIAL INTELLIGENCE ACT) AND AMENDING CERTAIN UNION\\nLEGISLATIVE ACTS\\x0cEN\\nEXPLANATORY MEMORANDUM\\n1. CONTEXT OF THE PROPOSAL\\n1.1. Reasons for and objectives of the proposal\\nThis explanatory memorandum accompanies the proposal for a Regulation laying down\\nharmonised rules on artificial intelligence (Artificial Intelligence Act). Artificial Intelligence\\n(AI) is a fast evolving family of technologies that can bring a wide array of economic and\\nsocietal benefits across the entire spectrum of industries and social activities. By improving\\nprediction, optimising operations and resource allocation, and personalising service delivery,\\nthe use of artificial intelligence can support socially and environmentally beneficial outcomes\\nand provide key competitive advantages to companies and the European economy. ',\n",
       " 'Such\\naction is especially needed in high-impact sectors, including climate change, environment and\\nhealth, the public sector, finance, mobility, home affairs and agriculture. However, the same\\nelements and techniques that power the socio-economic benefits of AI can also bring about\\nnew risks or negative consequences for individuals or the society. In light of the speed of\\ntechnological change and possible challenges, the EU is committed to strive for a balanced\\napproach. It is in the Union interest to preserve the EU‚Äôs technological leadership and to\\nensure that Europeans can benefit from new technologies developed and functioning\\naccording to Union values, fundamental rights and principles.\\n',\n",
       " 'This proposal delivers on the political commitment by President von der Leyen, who\\nannounced in her political guidelines for the 2019-2024 Commission ‚ÄúA Union that strives for\\nmore‚Äù1, that the Commission would put forward legislation for a coordinated European\\napproach on the human and ethical implications of AI. Following on that announcement, on\\n19 February 2020 the Commission published the White Paper on AI - A European approach\\nto excellence and trust2. The White Paper sets out policy options on how to achieve the twin\\nobjective of promoting the uptake of AI and of addressing the risks associated with certain\\nuses of such technology. This proposal aims to implement the second objective for the\\ndevelopment of an ecosystem of trust by proposing a legal framework for trustworthy AI. ',\n",
       " 'The\\nproposal is based on EU values and fundamental rights and aims to give people and other\\nusers the confidence to embrace AI-based solutions, while encouraging businesses to develop\\nthem. AI should be a tool for people and be a force for good in society with the ultimate aim\\nof increasing human well-being. Rules for AI available in the Union market or otherwise\\naffecting people in the Union should therefore be human centric, so that people can trust that\\nthe technology is used in a way that is safe and compliant with the law, including the respect\\nof fundamental rights. Following the publication of the White Paper, the Commission\\nlaunched a broad stakeholder consultation, which was met with a great interest by a large\\nnumber of stakeholders who were largely supportive of regulatory intervention to address the\\nchallenges and concerns raised by the increasing use of AI.\\n',\n",
       " 'The proposal also responds to explicit requests from the European Parliament (EP) and the\\nEuropean Council, which have repeatedly expressed calls for legislative action to ensure a\\nwell-functioning internal market for artificial intelligence systems (‚ÄòAI systems‚Äô) where both\\nbenefits and risks of AI are adequately addressed at Union level. It supports the objective of\\nthe Union being a global leader in the development of secure, trustworthy and ethical artificial\\n2 European Commission, White Paper on Artificial Intelligence - A European approach to excellence and\\ntrust, COM(2020) 65 final, 2020.\\x0cEN\\nintelligence as stated by the European Council3 and ensures the protection of ethical principles\\nas specifically requested by the European Parliament4.\\nIn 2017, the European Council called for a ‚Äòsense of urgency to address emerging trends‚Äô\\nincluding ‚Äòissues such as artificial intelligence ‚Ä¶, while at the same time ensuring a high\\nlevel of data protection, digital rights and ethical standards‚Äô5. ']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = [doc.content for doc in docs]\n",
    "inputs[0][0:500]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The document has been correctly batched, from one big document to 355 strings, 150-character long at maximum. This list of strings can now be used as input to generate a instruction dataset using `distilabel`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating instructions with SelfInstructTask\n",
    "\n",
    "With out Inference Endpoint up and running, we should be able to generate instructions with distilabel. These instructions, made by the LLM through our endpoint, will form an instruction dataset, with instructions created from the data we just extracted.\n",
    "\n",
    "For this example, we are using a subset of 50 batches generated in the section above, to be gentle on performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input'],\n",
       "    num_rows: 50\n",
       "})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instructions_dataset = Dataset.from_dict({\"input\": inputs[0:50]})\n",
    "\n",
    "instructions_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the `SelfInstructTask` class we can generate a Self-Instruct specitification for building the prompts, as done in the [Self-Instruct paper](https://arxiv.org/abs/2212.10560). `distilabel` will start from human-made input, in this case, the batches we created from the AI Act pdf, and it will generate instructions based on it. These instructions can then be reviewed using Argilla to keep the best ones.\n",
    "\n",
    "An application description can be passed as a parameter to specify the behaviour of the model; we want a model capable of answering our questions about the AI Act.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions_task = SelfInstructTask(\n",
    "    application_description=\"A assistant that can answer questions about the AI Act made by the European Union.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now define a generator, passing the `SelfInstructTask` object, and create a `Pipeline` object.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions_generator = InferenceEndpointsLLM(\n",
    "    endpoint_name=os.getenv(\"HF_INFERENCE_ENDPOINT_NAME\"),  # type: ignore\n",
    "    endpoint_namespace=os.getenv(\"HF_NAMESPACE\"),  # type: ignore\n",
    "    token=os.getenv(\"HF_TOKEN\") or None,\n",
    "    task=instructions_task,\n",
    ")\n",
    "\n",
    "instructions_pipeline = Pipeline(generator=instructions_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our pipeline is ready to be used to generate instructions. Let's do it!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_instructions = instructions_pipeline.generate(\n",
    "    dataset=instructions_dataset, num_generations=1, batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pipeline has succesfully generated instructions given the topics and the behaviour passed as input. Let's gather all those instructions and see how the look.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of generated instructions: 178\n",
      "What are the reasons for and objectives of the proposal for a Regulation laying down harmonised rules on artificial intelligence?\n",
      "How can artificial intelligence improve prediction, optimise operations and resource allocation, and personalise service delivery?\n",
      "What benefits can artificial intelligence bring to the European economy and society as a whole?\n",
      "How can the use of artificial intelligence support socially and environmentally beneficial outcomes?\n",
      "What are the high-impact sectors that require AI action according to the AI Act by the European Union?\n"
     ]
    }
   ],
   "source": [
    "instructions = []\n",
    "for generations in generated_instructions[\"instructions\"]:\n",
    "    for generation in generations:\n",
    "        instructions.extend(generation)\n",
    "\n",
    "print(f\"Number of generated instructions: {len(instructions)}\")\n",
    "\n",
    "for instruction in instructions[:5]:\n",
    "    print(instruction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These initial intructions form our instruction dataset. Following the human-in-the-loop approach, we should push the instructions to Argilla to visualize them and be able to rank them in terms of quality. Those annotations are essential to make quality data, ensuring a better performance of the final model. Nevertheless, this step is optional.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pushing the instruction dataset to Argilla to visualize and annotate.\n",
    "\n",
    "Let's take a quick look at the instructions generated by `SelfInstructTask`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'EN EN\\nEUROPEAN\\nCOMMISSION\\nProposal for a\\nREGULATION OF THE EUROPEAN PARLIAMENT AND OF THE COUNCIL\\nLAYING DOWN HARMONISED RULES ON ARTIFICIAL INTELLIGENCE\\n(ARTIFICIAL INTELLIGENCE ACT) AND AMENDING CERTAIN UNION\\nLEGISLATIVE ACTS\\x0cEN\\nEXPLANATORY MEMORANDUM\\n1. CONTEXT OF THE PROPOSAL\\n1.1. Reasons for and objectives of the proposal\\nThis explanatory memorandum accompanies the proposal for a Regulation laying down\\nharmonised rules on artificial intelligence (Artificial Intelligence Act). Artificial Intelligence\\n(AI) is a fast evolving family of technologies that can bring a wide array of economic and\\nsocietal benefits across the entire spectrum of industries and social activities. By improving\\nprediction, optimising operations and resource allocation, and personalising service delivery,\\nthe use of artificial intelligence can support socially and environmentally beneficial outcomes\\nand provide key competitive advantages to companies and the European economy. ',\n",
       " 'generation_model': ['argilla/notus-7b-v1'],\n",
       " 'generation_prompt': ['You are an expert prompt writer, writing the best and most diverse prompts for a variety of tasks. You are given a task description and a set of instructions for how to write the prompts for an specific AI application.\\n# Task Description\\nDevelop 5 user queries that can be received by the given AI application and applicable to the provided context. Emphasize diversity in verbs and linguistic structures within the model\\'s textual capabilities.\\n\\n# Criteria for Queries\\nIncorporate a diverse range of verbs, avoiding repetition.\\nEnsure queries are compatible with AI model\\'s text generation functions and are limited to 1-2 sentences.\\nDesign queries to be self-contained and standalone.\\nBlend interrogative (e.g., \"What is the significance of x?\") and imperative (e.g., \"Detail the process of x.\") styles.\\nWrite each query on a separate line and avoid using numbered lists or bullet points.\\n\\n# AI Application\\nA assistant that can answer questions about the AI Act made by the European Union.\\n\\n# Context\\nEN EN\\nEUROPEAN\\nCOMMISSION\\nProposal for a\\nREGULATION OF THE EUROPEAN PARLIAMENT AND OF THE COUNCIL\\nLAYING DOWN HARMONISED RULES ON ARTIFICIAL INTELLIGENCE\\n(ARTIFICIAL INTELLIGENCE ACT) AND AMENDING CERTAIN UNION\\nLEGISLATIVE ACTS\\x0cEN\\nEXPLANATORY MEMORANDUM\\n1. CONTEXT OF THE PROPOSAL\\n1.1. Reasons for and objectives of the proposal\\nThis explanatory memorandum accompanies the proposal for a Regulation laying down\\nharmonised rules on artificial intelligence (Artificial Intelligence Act). Artificial Intelligence\\n(AI) is a fast evolving family of technologies that can bring a wide array of economic and\\nsocietal benefits across the entire spectrum of industries and social activities. By improving\\nprediction, optimising operations and resource allocation, and personalising service delivery,\\nthe use of artificial intelligence can support socially and environmentally beneficial outcomes\\nand provide key competitive advantages to companies and the European economy. \\n\\n# Output\\n'],\n",
       " 'raw_generation_responses': ['1. What are the reasons for and objectives of the proposal for a Regulation laying down harmonised rules on artificial intelligence?\\n2. How can artificial intelligence improve prediction, optimise operations and resource allocation, and personalise service delivery?\\n3. What benefits can artificial intelligence bring to the European economy and society as a whole?\\n4. How can the use of artificial intelligence support socially and environmentally beneficial outcomes?\\n5. What competitive advantages can companies gain from using artificial intelligence?'],\n",
       " 'instructions': [['What are the reasons for and objectives of the proposal for a Regulation laying down harmonised rules on artificial intelligence?',\n",
       "   'How can artificial intelligence improve prediction, optimise operations and resource allocation, and personalise service delivery?',\n",
       "   'What benefits can artificial intelligence bring to the European economy and society as a whole?',\n",
       "   'How can the use of artificial intelligence support socially and environmentally beneficial outcomes?']]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_instructions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each input, i.e., each batch of the AI Act pdf file, we have a generator prompt, with general guidelines on how to behave, as well as the application description parameter. 4 instructions per input have been generated.\n",
    "\n",
    "Now it's the perfect time to upload the instruction dataset to Argilla, review it and manually annotate it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RemoteFeedbackDataset(\n",
       "   id=ee0f16c9-0838-4a19-a73d-14235e3a47b5\n",
       "   name=notus_AI_instructions\n",
       "   workspace=Workspace(id=29538109-004d-4be3-affc-a12606f51636, name=admin, inserted_at=2024-01-02 09:45:26.334713, updated_at=2024-01-02 09:45:26.334713)\n",
       "   url=https://ignacioct-argilla.hf.space/dataset/ee0f16c9-0838-4a19-a73d-14235e3a47b5/annotation-mode\n",
       "   fields=[RemoteTextField(id=UUID('95f30752-b096-4610-9ef0-c0d768e24d37'), client=None, name='input', title='input', required=True, type='text', use_markdown=False), RemoteTextField(id=UUID('4f86717f-4f8e-410d-aecb-366203138dd5'), client=None, name='instruction', title='instruction', required=True, type='text', use_markdown=False)]\n",
       "   questions=[RemoteRatingQuestion(id=UUID('800c04a6-f51f-4a7e-adda-3ee527bcd6d6'), client=None, name='instruction-rating', title='How would you rate the generated instruction?', description=None, required=True, type='rating', values=[1, 2, 3, 4, 5, 6, 7, 8, 9, 10])]\n",
       "   guidelines=None\n",
       "   metadata_properties=[RemoteIntegerMetadataProperty(id=UUID('24271cde-069b-475f-821c-f1d5e8649007'), client=<httpx.Client object at 0x19d0ea890>, name='length-input', title='length-input', visible_for_annotators=True, type='integer', min=None, max=None), RemoteIntegerMetadataProperty(id=UUID('f6ae43f0-cadb-4770-a260-681ffa6510cb'), client=<httpx.Client object at 0x19d0ea890>, name='length-instruction', title='length-instruction', visible_for_annotators=True, type='integer', min=None, max=None)]\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instructions_rg_dataset = generated_instructions.to_argilla()\n",
    "instructions_rg_dataset.push_to_argilla(name=f\"notus_AI_instructions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Argilla UI, each tuple input-instruction is visualized individually, and can be individually annotated.\n",
    "\n",
    "![](../assets/tutorials-assets/instrucion_dataset_ui.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a Preference Dataset using an Ultrafeedback text quality task.\n",
    "\n",
    "Once we have our instruction dataset, we are going to create a preference dataset through the UltraFeedback text quality task. This is a type of task used in NLP used to evaluate the quality of text generated; our goal is to provide detailed feedback on the quality of the generated text, beyond a binary label.\n",
    "\n",
    "Our `pipeline()` method allows us to create a `Pipeline` instance with the provided LLMs for a given task, which is useful whenever you want to use a pre-defined or custom `Pipeline` for a given task. We will specify our task and subtask, the generator we want to use (in this case, one based in a Llama2 Text Generator Task) and our OpenAI API key.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/03/24 11:10:19] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> INFO:distilabel:Since no `labeller` was provided, `OpenAILLM` will be  <a href=\"file:///Users/ignacio/Documents/recognai/distilabel/src/distilabel/pipeline.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">pipeline.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/ignacio/Documents/recognai/distilabel/src/distilabel/pipeline.py#846\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">846</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         used as the default labeller with `UltraFeedback`.                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/03/24 11:10:19]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m INFO:distilabel:Since no `labeller` was provided, `OpenAILLM` will be  \u001b]8;id=781763;file:///Users/ignacio/Documents/recognai/distilabel/src/distilabel/pipeline.py\u001b\\\u001b[2mpipeline.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=166507;file:///Users/ignacio/Documents/recognai/distilabel/src/distilabel/pipeline.py#846\u001b\\\u001b[2m846\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         used as the default labeller with `UltraFeedback`.                     \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preference_pipeline = pipeline(\n",
    "    \"preference\",\n",
    "    \"text-quality\",\n",
    "    generator=InferenceEndpointsLLM(\n",
    "        endpoint_name=os.getenv(\"HF_INFERENCE_ENDPOINT_NAME\"),  # type: ignore\n",
    "        endpoint_namespace=os.getenv(\"HF_NAMESPACE\", None),\n",
    "        task=Llama2TextGenerationTask(),\n",
    "        max_new_tokens=256,\n",
    "        num_threads=2,\n",
    "        temperature=0.3,\n",
    "    ),\n",
    "    max_new_tokens=256,\n",
    "    num_threads=2,\n",
    "    openai_api_key=os.getenv(\"OPENAI_API_KEY\"),\n",
    "    temperature=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to retrieve our instruction dataset from Argilla, as it will be the input of this pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input', 'instruction', 'instruction-rating', 'instruction-rating-suggestion', 'instruction-rating-suggestion-metadata', 'external_id', 'metadata'],\n",
       "    num_rows: 100\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remote_dataset = rg.FeedbackDataset.from_argilla(\n",
    "    \"notus_AI_instructions\", workspace=\"admin\"\n",
    ")\n",
    "instructions_dataset = remote_dataset.pull(max_records=100)  # get first 100 records\n",
    "\n",
    "instructions_dataset = instructions_dataset.format_as(\"datasets\")\n",
    "instructions_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'EN EN\\nEUROPEAN\\nCOMMISSION\\nProposal for a\\nREGULATION OF THE EUROPEAN PARLIAMENT AND OF THE COUNCIL\\nLAYING DOWN HARMONISED RULES ON ARTIFICIAL INTELLIGENCE\\n(ARTIFICIAL INTELLIGENCE ACT) AND AMENDING CERTAIN UNION\\nLEGISLATIVE ACTS\\x0cEN\\nEXPLANATORY MEMORANDUM\\n1. CONTEXT OF THE PROPOSAL\\n1.1. Reasons for and objectives of the proposal\\nThis explanatory memorandum accompanies the proposal for a Regulation laying down\\nharmonised rules on artificial intelligence (Artificial Intelligence Act). Artificial Intelligence\\n(AI) is a fast evolving family of technologies that can bring a wide array of economic and\\nsocietal benefits across the entire spectrum of industries and social activities. By improving\\nprediction, optimising operations and resource allocation, and personalising service delivery,\\nthe use of artificial intelligence can support socially and environmentally beneficial outcomes\\nand provide key competitive advantages to companies and the European economy.',\n",
       " 'instruction': 'What are the reasons for and objectives of the proposal for a Regulation laying down harmonised rules on artificial intelligence?',\n",
       " 'instruction-rating': [],\n",
       " 'instruction-rating-suggestion': None,\n",
       " 'instruction-rating-suggestion-metadata': {'type': None,\n",
       "  'score': None,\n",
       "  'agent': None},\n",
       " 'external_id': None,\n",
       " 'metadata': '{\"length-input\": 964, \"length-instruction\": 129}'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "instructions_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before generating the text based on our instructions, we need to mingle a little bit with the dataset. From the previous section, we still have our old input, the batches from the PDF. We have to change that to the instructions that we generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instructions_dataset = instructions_dataset.rename_columns({\"input\": \"context\"})\n",
    "instructions_dataset = instructions_dataset.rename_column({\"instruction\", \"input\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's build a dataset by using the pipeline we just created, and the topics from which our instructions were generated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preference_dataset = preference_pipeline.generate(\n",
    "    instructions_dataset,  # type: ignore\n",
    "    num_generations=2,\n",
    "    batch_size=8,\n",
    "    enable_checkpoints=True,\n",
    "    display_progress_bar=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at an instance of the preference dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': 'EN EN\\nEUROPEAN\\nCOMMISSION\\nProposal for a\\nREGULATION OF THE EUROPEAN PARLIAMENT AND OF THE COUNCIL\\nLAYING DOWN HARMONISED RULES ON ARTIFICIAL INTELLIGENCE\\n(ARTIFICIAL INTELLIGENCE ACT) AND AMENDING CERTAIN UNION\\nLEGISLATIVE ACTS\\x0cEN\\nEXPLANATORY MEMORANDUM\\n1. CONTEXT OF THE PROPOSAL\\n1.1. Reasons for and objectives of the proposal\\nThis explanatory memorandum accompanies the proposal for a Regulation laying down\\nharmonised rules on artificial intelligence (Artificial Intelligence Act). Artificial Intelligence\\n(AI) is a fast evolving family of technologies that can bring a wide array of economic and\\nsocietal benefits across the entire spectrum of industries and social activities. By improving\\nprediction, optimising operations and resource allocation, and personalising service delivery,\\nthe use of artificial intelligence can support socially and environmentally beneficial outcomes\\nand provide key competitive advantages to companies and the European economy.',\n",
       " 'input': 'What are the reasons for and objectives of the proposal for a Regulation laying down harmonised rules on artificial intelligence?',\n",
       " 'instruction-rating': [],\n",
       " 'instruction-rating-suggestion': None,\n",
       " 'instruction-rating-suggestion-metadata': {'agent': None,\n",
       "  'score': None,\n",
       "  'type': None},\n",
       " 'external_id': None,\n",
       " 'metadata': '{\"length-input\": 964, \"length-instruction\": 129}',\n",
       " 'generation_model': ['argilla/notus-7b-v1', 'argilla/notus-7b-v1'],\n",
       " 'generation_prompt': [\"<s>[INST] <<SYS>>\\nYou are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.<</SYS>>\\n\\nWhat are the reasons for and objectives of the proposal for a Regulation laying down harmonised rules on artificial intelligence? [/INST]\",\n",
       "  \"<s>[INST] <<SYS>>\\nYou are a helpful, respectful and honest assistant. Always answer as helpfully as possible, while being safe. Your answers should not include any harmful, unethical, racist, sexist, toxic, dangerous, or illegal content. Please ensure that your responses are socially unbiased and positive in nature.\\nIf a question does not make any sense, or is not factually coherent, explain why instead of answering something not correct. If you don't know the answer to a question, please don't share false information.<</SYS>>\\n\\nWhat are the reasons for and objectives of the proposal for a Regulation laying down harmonised rules on artificial intelligence? [/INST]\"],\n",
       " 'raw_generation_responses': ['\\n\\nThe proposal for a Regulation laying down harmonised rules on artificial intelligence (AI) aims to ensure a high level of safety and efficiency in the development, placement on the market, and use of AI systems while protecting fundamental rights, animal welfare, and the environment. The objectives of the proposal are:\\n\\n1. To ensure that AI systems are developed, designed, and deployed in a way that respects fundamental rights, animal welfare, and the environment.\\n\\n2. To establish a common European approach to AI, ensuring legal certainty and predictability for businesses and public authorities.\\n\\n3. To promote the development and use of AI in a responsible manner, taking into account the potential risks and benefits.\\n\\n4. To create a level playing field for businesses operating in the EU and to prevent unfair competition.\\n\\n5. To ensure that AI systems are safe and reliable, taking into account the state of the art in science and technology.\\n\\n6. To promote transparency and explainability of AI systems, enabling users to understand how decisions are made and to challenge them if necessary.\\n\\n7. To ensure that AI systems are secure, preventing unauthorized access, theft, or destruction of data.\\n\\n8. To promote the',\n",
       "  '\\n\\nThe proposal for a Regulation laying down harmonised rules on artificial intelligence (AI) aims to ensure a high level of safety and efficiency in the development, placement on the market, and use of AI systems while respecting fundamental rights, animal welfare, and the environment. The objectives of the proposal are:\\n\\n1. To ensure that AI systems are designed, developed, and deployed in a way that respects fundamental rights, animal welfare, and the environment.\\n\\n2. To establish a common European approach to AI that can be trusted by citizens and businesses.\\n\\n3. To ensure that AI systems are safe and work as intended.\\n\\n4. To prevent unlawful or malicious use of AI systems.\\n\\n5. To ensure that AI systems are secure and can withstand attacks.\\n\\n6. To promote responsible AI development and use.\\n\\n7. To ensure that AI systems are transparent and can be explained.\\n\\n8. To promote fair and non-discriminatory AI.\\n\\n9. To promote the use of AI that respects human autonomy, including the right to make decisions that affect their lives.\\n\\n10. To ensure that AI systems are reliable and robust.\\n\\n1'],\n",
       " 'generations': ['\\n\\nThe proposal for a Regulation laying down harmonised rules on artificial intelligence (AI) aims to ensure a high level of safety and efficiency in the development, placement on the market, and use of AI systems while protecting fundamental rights, animal welfare, and the environment. The objectives of the proposal are:\\n\\n1. To ensure that AI systems are developed, designed, and deployed in a way that respects fundamental rights, animal welfare, and the environment.\\n\\n2. To establish a common European approach to AI, ensuring legal certainty and predictability for businesses and public authorities.\\n\\n3. To promote the development and use of AI in a responsible manner, taking into account the potential risks and benefits.\\n\\n4. To create a level playing field for businesses operating in the EU and to prevent unfair competition.\\n\\n5. To ensure that AI systems are safe and reliable, taking into account the state of the art in science and technology.\\n\\n6. To promote transparency and explainability of AI systems, enabling users to understand how decisions are made and to challenge them if necessary.\\n\\n7. To ensure that AI systems are secure, preventing unauthorized access, theft, or destruction of data.\\n\\n8. To promote the',\n",
       "  '\\n\\nThe proposal for a Regulation laying down harmonised rules on artificial intelligence (AI) aims to ensure a high level of safety and efficiency in the development, placement on the market, and use of AI systems while respecting fundamental rights, animal welfare, and the environment. The objectives of the proposal are:\\n\\n1. To ensure that AI systems are designed, developed, and deployed in a way that respects fundamental rights, animal welfare, and the environment.\\n\\n2. To establish a common European approach to AI that can be trusted by citizens and businesses.\\n\\n3. To ensure that AI systems are safe and work as intended.\\n\\n4. To prevent unlawful or malicious use of AI systems.\\n\\n5. To ensure that AI systems are secure and can withstand attacks.\\n\\n6. To promote responsible AI development and use.\\n\\n7. To ensure that AI systems are transparent and can be explained.\\n\\n8. To promote fair and non-discriminatory AI.\\n\\n9. To promote the use of AI that respects human autonomy, including the right to make decisions that affect their lives.\\n\\n10. To ensure that AI systems are reliable and robust.\\n\\n1'],\n",
       " 'labelling_model': 'gpt-3.5-turbo',\n",
       " 'labelling_prompt': [{'content': 'Your role is to evaluate text quality based on given criteria.',\n",
       "   'role': 'system'},\n",
       "  {'content': \"\\n# General Text Quality Assessment\\nEvaluate the model's outputs based on various criteria:\\n1. **Correctness & Informativeness**: Does the output provide accurate and helpful information?\\n2. **Honesty & Uncertainty**: How confidently does the model convey its information, and does it express uncertainty appropriately?\\n3. **Truthfulness & Hallucination**: Does the model introduce misleading or fabricated details?\\n4. **Instruction Following**: Does the model's output align with given instructions and the user's intent?\\nYour role is to provide a holistic assessment considering all the above factors.\\n\\n**Scoring**: Rate outputs 1 to 5 based on the overall quality, considering all aspects:\\n\\n1. **Low Quality**: Contains inaccuracies, may be entirely wrong or has severe hallucinations.\\n2. **Moderate Quality**: Addresses some aspects, but has errors or is partially aligned with instructions.\\n3. **Good**: Generally accurate but may contain minor errors or slight deviations.\\n4. **Very Good**: Near perfect, with minor issues in terms of alignment or confidence.\\n5. **Excellent**: Accurate, confident, aligned with instructions, and free of hallucinations.\\n\\n---\\n\\n## Format\\n\\n### Input\\nInstruction: [Specify task goal and restrictions]\\n\\nTexts:\\n\\n<text 1> [Text 1]\\n<text 2> [Text 2]\\n\\n### Output\\n\\n#### Output for Text 1\\nRating: [Rating for text 1]\\nRationale: [Rationale for the rating in short sentences]\\n\\n#### Output for Text 2\\nRating: [Rating for text 2]\\nRationale: [Rationale for the rating in short sentences]\\n\\n---\\n\\n## Annotation\\n\\n### Input\\nInstruction: How can artificial intelligence improve prediction, optimise operations and resource allocation, and personalise service delivery?\\n\\nTexts:\\n\\n<text 1> \\n\\nArtificial intelligence (AI) has the potential to revolutionize various industries and sectors by improving prediction, optimizing operations, and personalizing service delivery. Here are some ways AI can achieve these benefits:\\n\\n1. Prediction: AI can analyze vast amounts of data and identify patterns, trends, and anomalies. This enables it to make accurate predictions about future events, such as weather forecasting, stock market trends, and disease outbreaks. AI can also predict customer behavior, preferences, and needs, allowing businesses to tailor their products and services accordingly.\\n\\n2. Optimization: AI can optimize operations by automating routine tasks, reducing errors, and improving efficiency. For instance, AI-powered robots can perform repetitive tasks in manufacturing, while AI algorithms can optimize supply chain management, logistics, and transportation. AI can also optimize resource allocation, such as energy consumption, water usage, and waste management.\\n\\n3. Personalization: AI can personalize service delivery by analyzing customer data, preferences, and behavior. This enables businesses to offer customized recommendations, promotions, and offers, increasing customer satisfaction and loyalty. AI can also personalize content, such as news, music, and videos, based on\\n<text 2> \\n\\nArtificial intelligence (AI) has the potential to revolutionise various industries by improving prediction, optimising operations, and personalising service delivery. Here are some ways AI can achieve these benefits:\\n\\n1. Prediction: AI can analyse vast amounts of data and identify patterns that are not visible to humans. This ability enables it to make accurate predictions about future trends and events. For instance, AI can predict weather patterns, stock market trends, and disease outbreaks. This information can help businesses and governments make informed decisions and take proactive measures to mitigate risks.\\n\\n2. Optimisation: AI can optimise operations by identifying the most efficient ways to use resources. For example, AI-powered algorithms can optimise traffic flow, reduce energy consumption, and improve supply chain management. This results in cost savings, increased productivity, and reduced environmental impact.\\n\\n3. Personalisation: AI can analyse user data and preferences to provide personalised recommendations and experiences. For instance, AI-powered chatbots can understand user queries and provide relevant responses. AI can also recommend products and services based on user behaviour and preferences. This leads to increased customer satisfaction, loyalty, and revenue.\\n\\n4. Healthcare: AI can improve patient outcomes by\\n\\n### Output \",\n",
       "   'role': 'user'}],\n",
       " 'raw_labelling_response': '#### Output for Text 1\\nRating: 4\\nRationale: The text provides accurate and informative information about how artificial intelligence can improve prediction, optimize operations, and personalize service delivery. It mentions specific examples such as weather forecasting, stock market trends, disease outbreaks, and customer behavior analysis. However, there are minor errors and slight deviations in the wording and organization of the content.\\n\\n#### Output for Text 2\\nRating: 3\\nRationale: The text also provides accurate information about how artificial intelligence can improve prediction, optimize operations, and personalize service delivery. It mentions examples such as weather patterns, stock market trends, disease outbreaks, traffic flow optimization, energy consumption reduction, and supply chain management improvement. However, it lacks the mention of customer behavior analysis and the content is slightly less organized compared to Text 1.',\n",
       " 'rating': [4.0, 3.0],\n",
       " 'rationale': ['The text provides accurate and informative information about how artificial intelligence can improve prediction, optimize operations, and personalize service delivery. It mentions specific examples such as weather forecasting, stock market trends, disease outbreaks, and customer behavior analysis. However, there are minor errors and slight deviations in the wording and organization of the content.',\n",
       "  'The text also provides accurate information about how artificial intelligence can improve prediction, optimize operations, and personalize service delivery. It mentions examples such as weather patterns, stock market trends, disease outbreaks, traffic flow optimization, energy consumption reduction, and supply chain management improvement. However, it lacks the mention of customer behavior analysis and the content is slightly less organized compared to Text 1.']}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preference_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the preference dataset to Argilla to annotate.\n",
    "\n",
    "Once our preference dataset has been correctly generated, the Argilla UI is the best tool at our disposal to visualize it and annotate it. As for the instruction dataset, we just have to convert it to an Argilla Feedback Dataset, and push it to Argilla.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RemoteFeedbackDataset(\n",
       "   id=836caf37-0cac-4e1d-a625-8d2ca1cc9cb0\n",
       "   name=notus_AI_preference\n",
       "   workspace=Workspace(id=29538109-004d-4be3-affc-a12606f51636, name=admin, inserted_at=2024-01-02 09:45:26.334713, updated_at=2024-01-02 09:45:26.334713)\n",
       "   url=https://ignacioct-argilla.hf.space/dataset/836caf37-0cac-4e1d-a625-8d2ca1cc9cb0/annotation-mode\n",
       "   fields=[RemoteTextField(id=UUID('2986535e-d777-463e-9869-681ca720f523'), client=None, name='input', title='input', required=True, type='text', use_markdown=False), RemoteTextField(id=UUID('14981764-f68e-4355-8ab8-96b7608672d1'), client=None, name='generations-1', title='generations-1', required=True, type='text', use_markdown=False), RemoteTextField(id=UUID('2683d727-c3ed-4b87-86bd-fc7b534d0e40'), client=None, name='generations-2', title='generations-2', required=True, type='text', use_markdown=False)]\n",
       "   questions=[RemoteRatingQuestion(id=UUID('14e93689-f7cd-4d4e-9d22-e289a2526989'), client=None, name='generations-1-rating', title=\"What's the rating for generations-1?\", description=None, required=True, type='rating', values=[1, 2, 3, 4, 5]), RemoteRatingQuestion(id=UUID('afe87e30-f308-447e-947c-4fb122f3670d'), client=None, name='generations-2-rating', title=\"What's the rating for generations-2?\", description=None, required=True, type='rating', values=[1, 2, 3, 4, 5]), RemoteTextQuestion(id=UUID('6e9da984-c5a3-46f7-8fd2-c6931539a625'), client=None, name='rating-rationale', title=\"What's the rationale behind each rating?\", description=None, required=True, type='text', use_markdown=False)]\n",
       "   guidelines=None\n",
       "   metadata_properties=[RemoteIntegerMetadataProperty(id=UUID('88305798-5fcd-4110-8907-14691483582f'), client=<httpx.Client object at 0x19d0ea890>, name='length-input', title='length-input', visible_for_annotators=True, type='integer', min=None, max=None), RemoteIntegerMetadataProperty(id=UUID('d0c89d2a-636f-45f2-ab6d-f7ecf5ec8d94'), client=<httpx.Client object at 0x19d0ea890>, name='length-generations-1', title='length-generations-1', visible_for_annotators=True, type='integer', min=None, max=None), RemoteFloatMetadataProperty(id=UUID('bc7b40e9-704b-43a2-9d4d-156bb14b316b'), client=<httpx.Client object at 0x19d0ea890>, name='rating-generations-1', title='rating-generations-1', visible_for_annotators=True, type='float', min=None, max=None), RemoteIntegerMetadataProperty(id=UUID('3541767a-4728-4cf0-8529-39d4abd21db8'), client=<httpx.Client object at 0x19d0ea890>, name='length-generations-2', title='length-generations-2', visible_for_annotators=True, type='integer', min=None, max=None), RemoteFloatMetadataProperty(id=UUID('940955e1-3277-4001-a5f2-0be1a64eedab'), client=<httpx.Client object at 0x19d0ea890>, name='rating-generations-2', title='rating-generations-2', visible_for_annotators=True, type='float', min=None, max=None), RemoteFloatMetadataProperty(id=UUID('315007a1-b790-4653-a4c7-ede751556515'), client=<httpx.Client object at 0x19d0ea890>, name='distance-best-rating', title='distance-best-rating', visible_for_annotators=True, type='float', min=None, max=None)]\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uploading the Preference Dataset\n",
    "preference_rg_dataset = preference_dataset.to_argilla()\n",
    "\n",
    "# Adding the context as a metadata property in the new Feedback dataset, as this\n",
    "# information will be useful later.\n",
    "for record_feedback, record_huggingface in zip(\n",
    "    preference_rg_dataset, preference_dataset\n",
    "):\n",
    "    record_feedback.metadata[\"context\"] = record_huggingface[\"context\"]\n",
    "\n",
    "preference_rg_dataset.push_to_argilla(name=f\"notus_AI_preference\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Argilla UI, we can see the input (an instruction), and the two generations that the LLM created out of it.\n",
    "\n",
    "![](../assets/tutorials-assets/preference_dataset_ui.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "To conclude, we have gone through an end-to-end example of distilabel. We've set up an Inference Endpoint, defined a distilabel pipeline that extracts information from a PDF, created and manually reviewed the instruction and preference dataset created from that input. The final preference dataset is perfect for fine-tuning, and you can easily do this using the ArgillaTrainer from Argilla. Have a look at these resources if you want to go further:\n",
    "\n",
    "- [Train a Model with ArgillaTrainer](https://docs.argilla.io/en/latest/tutorials_and_integrations/tutorials/feedback/end2end_examples/train-model-006.html)\n",
    "- [‚ìÇÔ∏è Finetuning LLMs as chat assistants: Supervised Finetuning on Mistral 7B](https://docs.argilla.io/en/latest/tutorials_and_integrations/tutorials/feedback/training-llm-mistral-sft.html)\n",
    "- [üå† Improving RAG by Optimizing Retrieval and Reranking Models](https://docs.argilla.io/en/latest/tutorials_and_integrations/tutorials/feedback/fine-tuning-sentencesimilarity-rag.html)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "distilabel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
